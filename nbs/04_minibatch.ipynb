{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a21a95c9-1b17-4ca8-9757-8ff20a21f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ac1ba13-e447-4a2a-a363-d3f47782b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('/notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdf9c50e-b2cd-45a1-9852-ef1c77e32cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "import pickle, gzip, math, os, time, shutil, torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import tensor, nn\n",
    "import torch.nn.functional as F\n",
    "from fastcore.foundation import L\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4eabb75f-a110-4f83-8db1-aca924f69d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_close\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "plt.style.use('fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66a70fcc-17da-41ac-bf98-46b87217068c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../data/mnist.pkl.gz'), PosixPath('../data/.ipynb_checkpoints')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data = Path('./data')\n",
    "list(path_data.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeb9409-1cb5-48ac-94fe-39716f137619",
   "metadata": {},
   "source": [
    "## Conv size equations\n",
    "\n",
    "A square image of size $n$ convolved with a kernel of size $k$ with stride $s$ and padding $p$ will yield a square result of side:\n",
    "\n",
    "$$\\frac{n-k+2p+1}{s}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbff0aea-124c-40d6-b59b-019a07732c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_gz = path_data / 'mnist.pkl.gz'\n",
    "with gzip.open(path_gz, 'rb') as f: \n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419ebc3a-e08c-4af6-b2bd-471f17e8d918",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0484d1f7-0534-4da2-b694-e685a4bc48b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m = x_train.shape\n",
    "c = y_train.max() + 1\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c62415da-035d-459c-9739-6cfbcc9d94b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out)]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10fc474b-9300-41e5-a30c-5224b65c3bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(m, nh, 10)\n",
    "pred = model(x_train)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950dcc30-3b2e-4f0b-b8d0-a99f3f9fbf39",
   "metadata": {},
   "source": [
    "## Maximum Likelihood & Cross-Entropy\n",
    "\n",
    "Maximum likelihood estimator. Given a dataset $\\{x_1, x_2, \\dots, x_n\\}$ of i.i.d samples of a set $\\mathbb{X}$ with a corresponding set of labels $y_1, y_2, \\dots, y_n$ from a finite set $\\mathbb{Y}$. \n",
    "\n",
    "**We want to learn to predict the label y of any given x**\n",
    "\n",
    "We'll do so by learning a parametrized probability distribution $p_{\\text{model}}(x = y; \\theta)$. For a given $\\theta$, we get that the likelihood of our model given our dataset is:\n",
    "\n",
    "$$\\prod_i{p_{\\text{model}}(x_i = y_i; \\theta)}$$\n",
    "\n",
    "Thus, the maximum likelihood estimator $\\theta^*$ is given by:\n",
    "\n",
    "$$\\theta^* = \\text{argmax}_{\\theta} \\prod_i{p_\\text{model}(x_i = y_i; \\theta)}$$\n",
    "\n",
    "This is equivalent to (by the law of large numbers):\n",
    "\n",
    "$$\\theta^* = \\text{argmax}_\\theta\\frac1n\\sum_i \\log(p_{\\text{model}}(x_i = y_i;\\theta)) \\approx \\text{argmax}_\\theta\\mathbb{E}_{x \\in \\mathbb{X}}[\\log p_{\\text{model}}(x = y; \\theta)]$$\n",
    "$$ = \\text{argmax}_\\theta\\sum_{x \\in \\mathbb{X}} x\\log{p_{\\text{model}}(x = y ; \\theta)}$$\n",
    "\n",
    "We can also see that this is equivalent to:\n",
    "\n",
    "$$ \\theta^* = \\text{argmin}_\\theta - \\mathbb{E}_{x \\in \\mathbb{X}}[\\log p_{\\text{model}}(x = y; \\theta)] $$ \n",
    "$$= \\text{argmin}_\\theta - \\mathbb{E}_{x \\in \\mathbb{X}}[\\log p_{\\text{model}}(x = y; \\theta) - \\log\\hat{p}_\\text{data}(x = y)]$$\n",
    "\n",
    "Where $\\hat{p}_\\text{data}(x = y)$ is the true underlying probability that uniformly sampled $x$ has a corresponding label $y$. The latter is true as the underlying $\\hat{p}_\\text{data}$ distribution is independent of our paramemeters $\\theta$. The last equation is the same as:\n",
    "\n",
    "$$\\theta^* = \\text{argmin}_\\theta D_{KL}(p_\\text{model}|| \\hat{p}_\\text{data})$$\n",
    "\n",
    "Where $D_{KL}$ is the KL-Divergence from $Q$ to $P$. We know that $D_{KL}(P || Q) = H(P, Q) - H(P)$, where $H$ denotes (cross) entropy. We then see that:\n",
    "\n",
    "$$\\theta^* = \\text{argmin}_{\\theta} H(\\hat{p}_{\\text{data}}, p_{\\text{model}}) - H(\\hat{p}_{\\text{data}}) = \\text{argmin}_{\\theta} H(\\hat{p}_{\\text{data}}, p_{\\text{model}})$$\n",
    "\n",
    "**TL;DR:**\n",
    "\n",
    "$$\\text{argmax}_\\theta\\frac1n\\sum_i \\log(p_{\\text{model}}(x_i = y_i;\\theta))$$\n",
    "\n",
    "Is equivalent to minimizing the KL Divergence (and cross-entropy) from $\\hat{p}_\\text{data}$ and our model distribution $p_\\text{model} (x = y ; \\theta)$. This makes it a maximum likelihood estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70e74cc-d94f-4e7f-ab30-8c86317114af",
   "metadata": {},
   "source": [
    "## Sigmoid vs Softmax \n",
    "\n",
    "We define sigmoid as:\n",
    "\n",
    "$$\\text{sigmoid(x)} = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "And softmax as \n",
    "\n",
    "$$\\text{softmax(x)_i} = \\frac{e^{x_i}}{\\sum\\limits_{j} e^x_j}$$\n",
    "\n",
    "Softmax for the two category case turns into the sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b664722-c136-4b0f-9ac4-b71303c17492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+math.pow(math.e, -x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eced8f2-988f-419c-97e7-51c2bfce7e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-10, 10, 200)\n",
    "y = [sigmoid(t) for t in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f3fa2b0-bdb9-4d30-9089-b6d24ff97568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfGklEQVR4nO3deXTcdb3/8ec7a/eGNumW7nShpYCF0LKJlbUtS/2pV4twRcBblx/+9Kd3wYuX68Fz7nU5V6/+LoqIKLghqGiLqRUQQVZboGnSlrbpQpsmaZK26ZY2y8z798dMcRom7aSZme/M5PU4Z858l8/M953vfPPKN5/5LubuiIhI9ssLugAREUkOBbqISI5QoIuI5AgFuohIjlCgi4jkiIKgFlxaWuqTJ08OavEiIlnptddea3H3snjzAgv0yZMns2bNmqAWLyKSlczsrZ7mqctFRCRHKNBFRHKEAl1EJEco0EVEcoQCXUQkR5wy0M3sITNrMrOaHuabmX3HzGrNbJ2ZnZ/8MkVE5FQS2UP/MbDwJPMXAdOjj2XA9/peloiI9NYpj0N39+fNbPJJmiwBHvHIdXhfMbMSMxvr7g3JKlJE+g93JxR2usLdnkPhbtMi412hmPHQia/pDIXjvFeYztCJ46FwdNl4tIb4dXWf52/PO/H1J0474U0AuHLWaM6bUNK3FRVHMk4sKgd2xYzXRae9I9DNbBmRvXgmTpyYhEWLSNDcnSMdIfYd7qDlSDt7D3ew93A7e490RIaPtLPvSActhzs41hmiKxq8sUF9PFyPT8tlZjBq2ICMDfSEufsDwAMAFRUVuf2pieSAfUc6qNl9gKZD7ew9/Ldg3hsN7sh4O+1d4bivH1JcwMghRYwYXER5yQAGFxeQn2cU5Bn5eXnRZ6Mw/8TxgjwjPz/yXJCXR0G+Jf66PIu2j0wvyH/n6yLT894ezjPD7MTaY8cNO2GandDOTph2wuu6v2mKJSPQdwMTYsbHR6eJSBbpDIV5s+EQb+zazxs7W3lj53527G07oU1RQR6lg4sYOaSYkUOKmDF6KCOHFDEyZlrp4GJGRKcNKMwP6Kfpn5IR6MuBO83sUWA+cED95yKZr+ngMV7feTy8W1m3u5VjnZE97bKhxZw/sYSl8yZy7vjhlJcMZOSQYgYX5ad9r1MSd8pAN7NfAAuAUjOrA/4dKARw9/uBSmAxUAu0AbelqlgROX1doTBPbdjDk9UNrN3Zyu7WowAU5edxdvkwPjJvEnMnljB3YgnlJQMV3FkokaNcbjrFfAf+d9IqEpGk2nu4nUdX7+Knr7xFw4FjjB5WzIWTR3D7ZVOYO7GEs8cNo7hAXSO5ILDL54pIalXtauXhl3fwZFUDHaEwl00r5d4lc7jirFHk52nvOxcp0EVySHtXiMrqBh5+6S3W7mplcFE+S+dN4KMXT2LaqKFBlycppkAXyQHhsPPwyzu479laWg53MLV0MF++YTYfuGA8QwcUBl2epIkCXSTLNRw4yj8+XsWLtXu5bFopyy6fymXTSslTt0q/o0AXyWLLq+r50hPVdIWdr77/HD584QQdndKPKdBFstCBtk7uWV7D79bWM3diCd/60LuYXDo46LIkYAp0kSzzUm0LX3i8iqZD7Xzh6hl8asGZFOTr1gaiQBfJGp2hMF9b+SYPvrCdqWWD+c2nLknJBZ4keynQRbJAKOx8/rEqVlTV8/cXTeJfF89iYJFOBpITKdBFMpy782+/q2FFVT1fXHQWn3jPmUGXJBlKHW8iGe7rqzbx81d38ukFZyrM5aQU6CIZ7P7ntvK9P2/l5vkT+adrZwZdjmQ4BbpIhvr5qzv56so3ueG8cdy7ZI6OL5dTUqCLZKAVVfXc/dtq3juzjG9+6DxdTEsSokAXyTDPbmri//5yLRdOGsF3b76AQh1jLgnSliKSQf66fR+f+ulrzBwzlAc/VqFDE6VXFOgiGaLlcDvLfrKGccMH8vDt8ximqyRKL+k4dJEMce+KDbS1h/jVJy+gdEhx0OVIFtIeukgGeHZTE8ur6vn0e8/UjSjktCnQRQJ2pL2LLz1Rw7RRQ/jUAp04JKdPXS4iAfvmU5vZ3XqUxz95sW7WLH2iPXSRAK2ra+VHL27nI/MncuHkEUGXI1lOgS4SkM5QmLt+XU3pkGL+ZeFZQZcjOUBdLiIBeeiF7WxoOMj3bj6f4QN1iKL0nfbQRQKwc28b33p6M1fPHs3COWOCLkdyhAJdJM3cnbt/W01BXh73LjlbF92SpFGgi6TZE2/s5i9bWvjnhTMZO3xg0OVIDlGgi6TRviMdfOXJDcydWMLN8ycFXY7kGAW6SBp966nNHDrWxVfff64uiStJp0AXSZOWw+08tmYXH7xgPDPH6PR+ST4FukiaPPLSDtq7wnz83VODLkVyVEKBbmYLzWyTmdWa2V1x5k80s2fN7A0zW2dmi5Nfqkj2auvo4pFX3uLq2aOZNmpI0OVIjjploJtZPnAfsAiYDdxkZrO7NfsS8Ji7zwWWAt9NdqEi2eyx1btobevkk+/R3rmkTiJ76POAWnff5u4dwKPAkm5tHBgWHR4O1CevRJHs1hUK8+AL27lg0hlcMEnXa5HUSSTQy4FdMeN10WmxvgzcYmZ1QCXwmXhvZGbLzGyNma1pbm4+jXJFsk9lTSN1+4/yicu1dy6plawvRW8Cfuzu44HFwE/M7B3v7e4PuHuFu1eUlZUladEimcvd+f5zW5laNpirZo0OuhzJcYkE+m5gQsz4+Oi0WHcAjwG4+8vAAKA0GQWKZLOXtu5lff1Blr17Knk67lxSLJFAXw1MN7MpZlZE5EvP5d3a7ASuBDCzWUQCXX0q0u/d/9xWSocU87653XspRZLvlIHu7l3AncAqYCORo1nWm9m9ZnZjtNkXgH8wsyrgF8DH3N1TVbRINthQf5C/bGnhtksnM6BQdyKS1EvoeujuXknky87YaffEDG8ALk1uaSLZ7YHntzKoKJ9bdM0WSROdKSqSAnX721ixroGb5k1k+CDdvELSQ4EukgIPvbADA26/bErQpUg/okAXSbIDbZ08unonN5w3jvISXe9c0keBLpJkP331Ldo6QizTiUSSZgp0kSQ61hniRy/u4PIZZcwaO+zULxBJIgW6SBI9s7GJlsPtfFx95xIABbpIElXWNDBycBGXTtOJ0pJ+CnSRJDnaEeJPG5u4ds4Y3V5OAqFAF0mS5zY3cbQzxHXnjA26FOmnFOgiSVJZ3cgZgwqZP0XXPJdgKNBFkuBYZ4hnNu7h2rPHUJCvXysJhrY8kSR4fnMzRzpCLFZ3iwRIgS6SBCtrGhk+sJCLzxwZdCnSjynQRfqovSvE0xv2cM3s0RSqu0UCpK1PpI9e2NLCofYuFp+r7hYJlgJdpI8qqxsZOqCAS8/UyUQSLAW6SB90dIV5akMjV88eTVGBfp0kWNoCRfrgxa0tHDzWpZOJJCMo0EX6YGV1A0OKC7hsurpbJHgKdJHT1BkK88cNe7hq1iiKC3QTaAmeAl3kNL28dS+tbZ06mUgyhgJd5DStrGlgcFE+l88oC7oUEUCBLnJaukJhVq3fwxWzRjOgUN0tkhkU6CKn4dXt+9h3pIPrzhkTdCkib1Ogi5yGyuoGBhbm854Zo4IuReRtCnSRXgqFnVXrG7nirFEMLFJ3i2QOBbpIL/11+z5aDnfo6BbJOAp0kV5aWdPAgMI8FszU0S2SWRToIr0QDjsraxpZMGMUg4sLgi5H5AQKdJFeWPPWfpoPtetSuZKREgp0M1toZpvMrNbM7uqhzYfMbIOZrTeznye3TJHMUFndQFFBHlecpaNbJPOc8n9GM8sH7gOuBuqA1Wa23N03xLSZDnwRuNTd95uZtnbJOeGw84eaRt4zo4wh6m6RDJTIHvo8oNbdt7l7B/AosKRbm38A7nP3/QDu3pTcMkWC98au/TQePKZL5UrGSiTQy4FdMeN10WmxZgAzzOxFM3vFzBbGeyMzW2Zma8xsTXNz8+lVLBKQyupGivLzuGKW/gGVzJSsL0ULgOnAAuAm4AdmVtK9kbs/4O4V7l5RVqZDviR7uDsrqxt49/RShg0oDLockbgSCfTdwISY8fHRabHqgOXu3unu24HNRAJeJCes3dVK/YFjOplIMloigb4amG5mU8ysCFgKLO/W5rdE9s4xs1IiXTDbklemSLBW1jRSmG9cNWt00KWI9OiUge7uXcCdwCpgI/CYu683s3vN7MZos1XAXjPbADwL/JO7701V0SLp5O5UVjdw6bRShg9Sd4tkroSOvXL3SqCy27R7YoYd+Hz0IZJTqncfoG7/Uf7PlepFlMymM0VFTqGyupGCPOOa2epukcymQBc5CXdnZU0DF585kpJBRUGXI3JSCnSRk1hff5C39rbpZCLJCgp0kZNYWdNAfp5xzdm61ZxkPgW6SA8iR7c0ctHUEYwYrO4WyXwKdJEebNpziO0tR3QykWQNBbpIDyrXNZBncM1sdbdIdlCgi/SgsqaReVNGUDa0OOhSRBKiQBeJY8ueQ9Q2HVZ3i2QVBbpIHL+vbsAMFuroFskiCnSROFZWN3LhpBGMGjYg6FJEEqZAF+mmtukwm/YcYtE52juX7KJAF+lmZXUDAIvmqP9csosCXaSbyppGLph0BmOGq7tFsosCXSTG9pYjbGw4yKI56m6R7KNAF4lReby7RYcrShZSoIvEWFnTwLsmlFBeMjDoUkR6TYEuErVzbxs1uw+yWEe3SJZSoItEVdbo6BbJbgp0kaiV1Q2cO344E0YMCroUkdOiQBcB6va3UVV3QHvnktUU6CJETvUH1H8uWU2BLkKk//zsccOYNHJw0KWInDYFuvR79a1HeWNnqy6VK1lPgS793sqaSHeLzg6VbKdAl35vZXUDZ40ZytSyIUGXItInCnTp1xoPHGPNW/vV3SI5QYEu/dofoicTKdAlFyjQpV+rrGlkxughTBul7hbJfgp06beaDh1j9Y59OplIcoYCXfqtVTWNuMN15yrQJTckFOhmttDMNplZrZnddZJ2HzAzN7OK5JUokhq/r27gzLLBTFd3i+SIUwa6meUD9wGLgNnATWY2O067ocBngVeTXaRIsu05eIxXt+/jhvPGYWZBlyOSFInsoc8Dat19m7t3AI8CS+K0+wrwNeBYEusTSYnfr2vAHa4/d1zQpYgkTSKBXg7sihmvi057m5mdD0xw99+f7I3MbJmZrTGzNc3Nzb0uViRZVqyrZ/bYYTq6RXJKn78UNbM84JvAF07V1t0fcPcKd68oKyvr66JFTsuufW28sbOVG87T3rnklkQCfTcwIWZ8fHTacUOBOcCfzWwHcBGwXF+MSqZ6cl3kZKLrdXSL5JhEAn01MN3MpphZEbAUWH58prsfcPdSd5/s7pOBV4Ab3X1NSioW6aMVVfXMnViiOxNJzjlloLt7F3AnsArYCDzm7uvN7F4zuzHVBYokU23TYTY0HOQGfRkqOaggkUbuXglUdpt2Tw9tF/S9LJHUeHJdPWY6mUhyk84UlX7D3VlRVc/8KSMYPWxA0OWIJJ0CXfqNjQ2H2Np8REe3SM5SoEu/sWJdPfl5potxSc5SoEu/cLy75bJppYwYXBR0OSIpoUCXfmHtrlbq9h9Vd4vkNAW69Asrqhooys/jmrNHB12KSMoo0CXnhcLOk+vqWTCzjGEDCoMuRyRlFOiS81bv2EfToXZ1t0jOU6BLzltRVc/AwnyunDUq6FJEUkqBLjmtMxRmZU0jV80ezaCihE6MFslaCnTJaS9t3cu+Ix3coFP9pR9QoEtOW1FVz9ABBbxnpq6/L7lPgS45q70rxKqaRq49ewzFBflBlyOScgp0yVnPbWrmUHuXjm6RfkOBLjlrxboGRgwu4pIzRwZdikhaKNAlJ7V1dPH0hj0smjOGwnxt5tI/aEuXnPTMxiaOdobU3SL9igJdctLyqnpGDyvmwskjgi5FJG0U6JJzdrce5U9vNvG+ueXk51nQ5YikjQJdcs4jL+8A4KMXTw60DpF0U6BLTmnr6OLRv+7i2rNHU14yMOhyRNJKgS455Yk3dnPgaCe3XTol6FJE0k6BLjnD3fnRizuYUz6MiklnBF2OSNop0CVn/GVLC7VNh7n90imY6ctQ6X8U6JIzfvTidkqHFHOdrqwo/ZQCXXLCtubDPLupmVsumqgLcUm/pUCXnPDwSzsoys/j5vmTgi5FJDAKdMl6B4528vhrddxw3jjKhhYHXY5IYBTokvUeX7OLto4Qt106OehSRAKlQJesFgo7P35pB/Mmj2BO+fCgyxEJVEKBbmYLzWyTmdWa2V1x5n/ezDaY2Toze8bM1JEpafH0xj3U7T+qvXMREgh0M8sH7gMWAbOBm8xsdrdmbwAV7n4u8Cvg68kuVCSeh17YTnnJQK6ePTroUkQCl8ge+jyg1t23uXsH8CiwJLaBuz/r7m3R0VeA8cktU+Sd1tcf4NXt+7j1kkkU6CYWIgkFejmwK2a8LjqtJ3cAK+PNMLNlZrbGzNY0NzcnXqVIHD9+cQcDC/P5cMXEoEsRyQhJ3a0xs1uACuAb8ea7+wPuXuHuFWVlZclctPQzLYfb+V1VPR+4oJzhgwqDLkckIxQk0GY3MCFmfHx02gnM7CrgbuA97t6enPJE4nvwL9vp6ArzsUt0VUWR4xLZQ18NTDezKWZWBCwFlsc2MLO5wPeBG929KfllivzNtubD/PCFbXzg/PFMGzUk6HJEMsYpA93du4A7gVXARuAxd19vZvea2Y3RZt8AhgCPm9laM1vew9uJ9Im7c++TGyguyOdfFs0MuhyRjJJIlwvuXglUdpt2T8zwVUmuSySuZzY28edNzXzpulmMGjog6HJEMoqO9ZKscawzxL1PbmDaqCHcesnkoMsRyTgJ7aGLZIIfPL+Nnfva+NnH51Oo485F3kG/FZIV6va3cd+fa1l8zhgunVYadDkiGUmBLlnhPyo3AnD3dd2vOiEixynQJeO9WNtCZXUjn14wjfKSgUGXI5KxFOiS0TpDYf59+XomjhjEssunBl2OSEZToEtGe/ilHdQ2Hebfrp/NgELdK1TkZBTokrGaDh3jv5/ewoKZZVw1a1TQ5YhkPAW6ZKyvrdxEe1eIe66fjZkFXY5IxlOgS0ZaWd3Ar1+v447LpjK1TNdrEUmEAl0yTs3uA3z+sSrmTizhc1dND7ockayhQJeM0nToGMseWUPJoEK+//cX6ItQkV7Qqf+SMY51hvjET15jf1snj3/yYl18S6SXFOiSEdydf32imjd2tvK9m89nTvnwoEsSyTrqcpGM8MDz2/jN67v5/NUzWHTO2KDLEclKCnQJ3DMb9/DVP7zJ9eeO5TNXTAu6HJGspUCXQL26bS+ffXQtc8YN5xsfPE/Hm4v0gQJdAvPoX3dy84OvMnpYMT/4aAUDi3REi0hf6EtRSbuuUJj/qHyTh17czuUzyvifj8xl2IDCoMsSyXoKdEmrg8c6+czP3+C5zc3cdulk7l48iwLdfUgkKRTokjY7Wo5wx8OreWtvG//5/nO4ad7EoEsSySkKdEmLl7a28OmfvY4BP/34fC6aOjLokkRyjgJdUqozFOaRl9/iPys3MqV0MD+89UImjhwUdFkiOUmBLinRFQrz27X1fOeZLezc18Z7Z5bx7Zv05adIKinQJalCYefJdfV8++ktbGs5wuyxw3jwoxVcOWuUjjEXSTEFuiRFOOz8YX0j//30ZjbvOczM0UO5/5bzuWb2GPLyFOQi6aBAlz5xd57asIdvPb2FjQ0HObNsMP/vprlcd85YBblIminQpde6QmGq6lp5bnMLT23Yw8aGg0waOYhvfug8lryrnHwFuUggFOiSkPrWozy/uZnntzTzwpYWDh7rIs/g3PElfP0D5/L+88t1gpBIwBToEtexzhCvbNvL85tbeH5LM7VNhwEYM2wAC+eM4fIZZVw2rZSSQUUBVyoixynQ+yl35+DRLupa26hvPUZ961F2H3/sP8qGhoN0dIUpKshj/pQRLL1wApfPKGP6qCE6WkUkQyUU6Ga2EPg2kA886O5f7Ta/GHgEuADYC3zY3Xckt1Tpja5QmKZD7exuPUp961Hq9h99O7Tro6F9pCN0wmuKCvIoLxnIuJIB3DJ/EpfPKGX+lJG6CqJIljhloJtZPnAfcDVQB6w2s+XuviGm2R3AfnefZmZLga8BH05FwacjHHZC7oTCkUdX2Akff/bIcyh0vE2YUBi6wmHCx5/d6Qqd+B5x3ydOm7cf0eld3ZZzwnMPNcZ7nx6XH3YOt3fRePAYobCfsB7OGFTIuJKBTB45mEvOLGX8GQMZVzIwGuIDKR1SpL1vkSyWyB76PKDW3bcBmNmjwBIgNtCXAF+ODv8K+B8zM3c/MVGS4Jerd/LA89v+Fm6hnkPueJvkV9F3+XkWeZhRkGfk5XV7NqMgPzL/7bZx2hQX5jEw+h7H2wwqKng7pMvPGEh5yQDGlQxkUJF62ERyWSK/4eXArpjxOmB+T23cvcvMDgAjgZbYRma2DFgGMHHi6V1pb8TgYs4aO+zkQdhTAMZtk0d+Hic8x3ufdzzsxGX01KYgL4+8PE58NrQnLCJJl9ZdNnd/AHgAoKKi4rT2m6+ePZqrZ49Oal0iIrkgkQOHdwMTYsbHR6fFbWNmBcBwIl+OiohImiQS6KuB6WY2xcyKgKXA8m5tlgO3Roc/CPwpFf3nIiLSs1N2uUT7xO8EVhE5bPEhd19vZvcCa9x9OfBD4CdmVgvsIxL6IiKSRgn1obt7JVDZbdo9McPHgL9LbmkiItIbuviGiEiOUKCLiOQIBbqISI5QoIuI5AgL6uhCM2sG3jrNl5fS7SzUDKG6ekd19V6m1qa6eqcvdU1y97J4MwIL9L4wszXuXhF0Hd2prt5RXb2XqbWprt5JVV3qchERyREKdBGRHJGtgf5A0AX0QHX1jurqvUytTXX1Tkrqyso+dBEReads3UMXEZFuFOgiIjkiYwPdzP7OzNabWdjMKrrN+6KZ1ZrZJjO7tofXTzGzV6Ptfhm99G+ya/ylma2NPnaY2doe2u0ws+pouzXJriPO8r5sZrtjalvcQ7uF0XVYa2Z3paGub5jZm2a2zsyeMLOSHtqlZX2d6uc3s+LoZ1wb3ZYmp6qWmGVOMLNnzWxDdPv/bJw2C8zsQMzne0+890pBbSf9XCziO9H1tc7Mzk9DTTNj1sNaMztoZp/r1iZt68vMHjKzJjOriZk2wsyeMrMt0eczenjtrdE2W8zs1nhtTsndM/IBzAJmAn8GKmKmzwaqgGJgCrAVyI/z+seApdHh+4FPpbje/wLu6WHeDqA0jevuy8A/nqJNfnTdTQWKout0dorrugYoiA5/DfhaUOsrkZ8f+DRwf3R4KfDLNHx2Y4Hzo8NDgc1x6loAPJmu7SnRzwVYDKwEDLgIeDXN9eUDjUROvAlkfQGXA+cDNTHTvg7cFR2+K952D4wAtkWfz4gOn9Hb5WfsHrq7b3T3TXFmLQEedfd2d98O1BK5kfXbLHLDziuI3LAa4GHgfamqNbq8DwG/SNUyUuDtm3+7ewdw/ObfKePuf3T3rujoK0TufhWURH7+JUS2HYhsS1daim8G6+4N7v56dPgQsJHIPXuzwRLgEY94BSgxs7FpXP6VwFZ3P90z0PvM3Z8nck+IWLHbUU9ZdC3wlLvvc/f9wFPAwt4uP2MD/STi3bS6+wY/EmiNCY94bZLp3cAed9/Sw3wH/mhmr0VvlJ0Od0b/7X2oh3/xElmPqXQ7kb25eNKxvhL5+U+4+Tlw/ObnaRHt4pkLvBpn9sVmVmVmK83s7DSVdKrPJehtaik971QFsb6OG+3uDdHhRiDeTZGTsu7SepPo7szsaWBMnFl3u/vv0l1PPAnWeBMn3zu/zN13m9ko4CkzezP6lzwldQHfA75C5BfwK0S6g27vy/KSUdfx9WVmdwNdwM96eJukr69sY2ZDgF8Dn3P3g91mv06kW+Fw9PuR3wLT01BWxn4u0e/IbgS+GGd2UOvrHdzdzSxlx4oHGujuftVpvCyRm1bvJfLvXkF0zypem6TUaJGbYr8fuOAk77E7+txkZk8Q+Xe/T78Iia47M/sB8GScWYmsx6TXZWYfA64HrvRo52Gc90j6+oqjNzc/r7M03vzczAqJhPnP3P033efHBry7V5rZd82s1N1TehGqBD6XlGxTCVoEvO7ue7rPCGp9xdhjZmPdvSHaBdUUp81uIn39x40n8v1hr2Rjl8tyYGn0CIQpRP7S/jW2QTQoniVyw2qI3MA6VXv8VwFvuntdvJlmNtjMhh4fJvLFYE28tsnSrd/yf/WwvERu/p3suhYC/wzc6O5tPbRJ1/rKyJufR/vofwhsdPdv9tBmzPG+fDObR+T3OKV/aBL8XJYDH40e7XIRcCCmqyHVevwvOYj11U3sdtRTFq0CrjGzM6JdpNdEp/VOOr75PZ0HkSCqA9qBPcCqmHl3EzlCYROwKGZ6JTAuOjyVSNDXAo8DxSmq88fAJ7tNGwdUxtRRFX2sJ9L1kOp19xOgGlgX3ZjGdq8rOr6YyFEUW9NUVy2RfsK10cf93etK5/qK9/MD9xL5gwMwILrt1Ea3palpWEeXEekqWxeznhYDnzy+nQF3RtdNFZEvly9JQ11xP5dudRlwX3R9VhNzdFqKaxtMJKCHx0wLZH0R+aPSAHRG8+sOIt+7PANsAZ4GRkTbVgAPxrz29ui2VgvcdjrL16n/IiI5Ihu7XEREJA4FuohIjlCgi4jkCAW6iEiOUKCLiOQIBbqISI5QoIuI5Ij/D0xha/MwqdSrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2c8e365-f644-4c8a-82dc-e8066b5d7743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return (x.exp()/(x.exp().sum(-1, keepdim=True))).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ebecf49-d9ec-4cc7-9aa3-a64893df8cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.37, -2.49, -2.36,  ..., -2.31, -2.28, -2.22],\n",
       "        [-2.37, -2.44, -2.44,  ..., -2.27, -2.26, -2.16],\n",
       "        [-2.48, -2.33, -2.28,  ..., -2.30, -2.30, -2.27],\n",
       "        ...,\n",
       "        [-2.33, -2.52, -2.34,  ..., -2.31, -2.21, -2.16],\n",
       "        [-2.38, -2.38, -2.33,  ..., -2.29, -2.26, -2.17],\n",
       "        [-2.33, -2.55, -2.36,  ..., -2.29, -2.27, -2.16]], grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 =log_softmax(pred); t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b11fcc3-1d1a-4a46-b318-eaff7be0e43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - x.exp().sum(-1, keepdim=True).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9c0e54a-4a49-4dc0-8ee7-30e00912f23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.37, -2.49, -2.36,  ..., -2.31, -2.28, -2.22],\n",
       "        [-2.37, -2.44, -2.44,  ..., -2.27, -2.26, -2.16],\n",
       "        [-2.48, -2.33, -2.28,  ..., -2.30, -2.30, -2.27],\n",
       "        ...,\n",
       "        [-2.33, -2.52, -2.34,  ..., -2.31, -2.21, -2.16],\n",
       "        [-2.38, -2.38, -2.33,  ..., -2.29, -2.26, -2.17],\n",
       "        [-2.33, -2.55, -2.36,  ..., -2.29, -2.27, -2.16]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = log_softmax(pred); t2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818c7038-b95e-4ced-b91a-2c4d54e0c5aa",
   "metadata": {},
   "source": [
    "### LogSumExp\n",
    "\n",
    "To avoid numerical intsabilities, over/underflows, we use the following equality\n",
    "\n",
    "$$\\log\\left(\\sum_{j=1}^ne^{x_j}\\right) = \\log\\left( e^{s}\\sum_j e^{x_j - s}\\right) = s + \\log\\left(\\sum_j e^{x_j - s}\\right)$$\n",
    "\n",
    "Where $s = max_i(x_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db97538e-093e-494c-ba76-f198a0253cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pred.max(-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6c653c9-8754-4c1a-9100-6f360776f45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([200]), torch.Size([50000, 1]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, s[:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21d61d27-9022-492a-aaa5-e872f2d87df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 200])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x - s[:, None]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "998d521a-d0ee-4c10-a377-20b11c0e2146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(s + (x - s[:, None]).exp().sum(-1).log()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8d6eb21-dbb6-4bd5-a9c8-97214ad55123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    s = x.max(-1)[0]\n",
    "    return (s + (x - s[:, None]).exp().sum(-1).log()).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec45894a-5871-44b3-af27-7b1eb9eab899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - logsumexp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f5ee96a-9533-412d-9a99-509d4aedf442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 10]), torch.Size([50000, 1]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape, logsumexp(pred).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab0ba579-c1d5-45c8-a8c3-04f535ca51d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.37, -2.49, -2.36,  ..., -2.31, -2.28, -2.22],\n",
       "        [-2.37, -2.44, -2.44,  ..., -2.27, -2.26, -2.16],\n",
       "        [-2.48, -2.33, -2.28,  ..., -2.30, -2.30, -2.27],\n",
       "        ...,\n",
       "        [-2.33, -2.52, -2.34,  ..., -2.31, -2.21, -2.16],\n",
       "        [-2.38, -2.38, -2.33,  ..., -2.29, -2.26, -2.17],\n",
       "        [-2.33, -2.55, -2.36,  ..., -2.29, -2.27, -2.16]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "feb9840c-ee34-4853-9e86-a9e87b49dcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - x.logsumexp(-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7322a4c8-ce24-4517-8434-466039d5b21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.37, -2.49, -2.36,  ..., -2.31, -2.28, -2.22],\n",
       "        [-2.37, -2.44, -2.44,  ..., -2.27, -2.26, -2.16],\n",
       "        [-2.48, -2.33, -2.28,  ..., -2.30, -2.30, -2.27],\n",
       "        ...,\n",
       "        [-2.33, -2.52, -2.34,  ..., -2.31, -2.21, -2.16],\n",
       "        [-2.38, -2.38, -2.33,  ..., -2.29, -2.26, -2.17],\n",
       "        [-2.33, -2.55, -2.36,  ..., -2.29, -2.27, -2.16]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abd373ad-3732-40ab-9f45-9a8cd7b02425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.37, -2.49, -2.36,  ..., -2.31, -2.28, -2.22],\n",
       "        [-2.37, -2.44, -2.44,  ..., -2.27, -2.26, -2.16],\n",
       "        [-2.48, -2.33, -2.28,  ..., -2.30, -2.30, -2.27],\n",
       "        ...,\n",
       "        [-2.33, -2.52, -2.34,  ..., -2.31, -2.21, -2.16],\n",
       "        [-2.38, -2.38, -2.33,  ..., -2.29, -2.26, -2.17],\n",
       "        [-2.33, -2.55, -2.36,  ..., -2.29, -2.27, -2.16]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred = log_softmax(pred)\n",
    "sm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9cfb961a-eba6-4a4a-819e-c55cd1355de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.20, -2.37, -2.36], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[range(3), y_train[:3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12a2b0b-224c-4a37-8a5a-54c9edb5d61d",
   "metadata": {},
   "source": [
    "## Cross-Entropy Loss\n",
    "\n",
    "From above, to get a maximum likelihood estimator we can simpyl average the logs of the probabilities. Using the $\\text{softmax}$, we'll train our network to output probabilities, so we can define our loss as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39fbc943-35ee-4a7e-b55a-aacf9e8c5dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(x, target):\n",
    "    return -x[range(target.shape[0]), target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3b42031-a856-4dc6-8f64-66b31ad7adc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.30, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = cross_entropy_loss(sm_pred, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ec511db-16aa-4402-b8ea-7eec34621771",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(F.nll_loss(F.log_softmax(pred, -1), y_train), loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af72322-acd7-40d5-8857-f032b7787627",
   "metadata": {},
   "source": [
    "In pytorch we can use `F.cross_entropy` directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb47ae25-0810-456b-ab81-0791d98d9eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(F.cross_entropy(pred, y_train), loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e429fb37-d4f8-403c-9458-5088a734be0b",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cba9878-e9bc-49f4-9458-cb2e4fdad950",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87fc22ce-32b6-405d-ba92-c532e81d8e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.09, -0.21, -0.08,  0.10, -0.04,  0.08, -0.04, -0.03,  0.01,  0.06], grad_fn=<SelectBackward0>),\n",
       " torch.Size([50, 10]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 50\n",
    "\n",
    "xb = x_train[0:bs] # minibatch\n",
    "preds = model(xb)\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31abe078-5f98-4467-9d34-5359b75753b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9,\n",
       "        3, 9, 8, 5, 9, 3])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "abf52144-cc1c-4073-920f-b4e599faef64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.30, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31e2648a-cea5-4b22-a9f7-23faf1846dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 9, 3, 8, 5, 9, 3, 9, 3, 9, 5, 3, 9, 9, 3, 9, 9, 5, 8, 7, 9, 5, 3, 8, 9, 5, 9, 5, 5, 9, 3, 5, 9, 7, 5, 7, 9, 9, 3, 9, 3, 5, 3, 8,\n",
       "        3, 5, 9, 5, 9, 5])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c55bedc9-3810-450f-a842-11205a160645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def accuracy(out, yb): return (out.argmax(dim=1) == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b9bb1ea3-853e-4043-849a-515f6b9e519e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.08)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b1c9cb03-fb89-45f9-98bb-0b4397c3fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5 \n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d3e8cd1-66d0-43b2-a9dd-98c60f84c225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def report(loss, preds, yb): print(f'{loss:.2f}, {accuracy(preds, yb):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "82369000-a6d9-4016-9c49-908cbf4ce252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.30, 0.08\n"
     ]
    }
   ],
   "source": [
    "xb, yb = x_train[:bs], y_train[:bs]\n",
    "preds = model(xb)\n",
    "report(loss_func(preds, yb), preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e671923-d131-460c-87c1-02167f9a3ab3",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "695f3543-a3de-46f0-9c61-2f5203f095cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12, 0.98\n",
      "0.12, 0.94\n",
      "0.08, 0.96\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n, i+bs))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias -= l.bias.grad * lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias.grad.zero_()\n",
    "                \n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da085d21-832e-4201-a53c-48f74e24efb8",
   "metadata": {},
   "source": [
    "## Use parameters and optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b74c2b6-6716-402f-a6bd-c9b16e66e23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module(\n",
       "  (foo): Linear(in_features=3, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = nn.Module()\n",
    "m1.foo = nn.Linear(3, 4)\n",
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c9cd5b7-cc79-4340-8155-00bada8865ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('foo', Linear(in_features=3, out_features=4, bias=True))]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc0e7fb0-25ed-4e7e-941a-efa862266639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.57,  0.43, -0.30],\n",
       "         [ 0.13, -0.32, -0.24],\n",
       "         [ 0.51,  0.04,  0.22],\n",
       "         [ 0.13, -0.17, -0.24]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.01, -0.51, -0.39,  0.56], requires_grad=True)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "739b1b0a-4d3b-498a-a583-5dd233a7bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x): return self.l2(self.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f099b1f0-4990-44cb-84d0-ec0f8a861031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=50, bias=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP(m, nh, 10)\n",
    "model.l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "00a40105-c63a-4913-8a12-56bfb31a9b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d0024a5-c355-492e-bfd5-52c5ffea5136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: Linear(in_features=784, out_features=50, bias=True)\n",
      "l2: Linear(in_features=50, out_features=10, bias=True)\n",
      "relu: ReLU()\n"
     ]
    }
   ],
   "source": [
    "for name, l in model.named_children(): print(f\"{name}: {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "814db1e0-e7fc-4b63-ac45-bfc035bd1a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "84a1a65b-dd55-4fbe-a7dc-3484889404cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, n, bs):\n",
    "            s = slice(i, min(n, i+bs))\n",
    "            xb, yb = x_train[s], y_train[s]\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "                \n",
    "        report(loss, preds, yb)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cc684bf0-ef0d-4111-8993-43be2572b8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19, 0.96\n",
      "0.11, 0.96\n",
      "0.04, 1.00\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2e0b25c5-3450-47fa-9a46-1a5d014f54a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule:\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        self._modules = {}\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "        \n",
    "    def __setattr__(self, k, v):\n",
    "        if not k.startswith(\"_\"): self._modules[k] = v\n",
    "        super().__setattr__(k, v)\n",
    "    \n",
    "    def parameters(self):\n",
    "        for l in self._modules.values(): yield from l.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cdf8b724-7558-435a-ac28-67b21b288340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MyModule at 0x7f142c136910>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = MyModule(m, nh, 10)\n",
    "mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4acc0681-89f0-4a86-a52c-80f3b4b36f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in mdl.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5d93c8-ddd0-40b2-8234-d052ffee2d35",
   "metadata": {},
   "source": [
    "# Register Modules\n",
    "\n",
    "We can keep the modules in a list, but then have to manually register them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "41222b3d-b185-4f36-814f-3568f1542b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "70977d41-39dd-47e8-b2cf-365043fcca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8902383e-b843-4dff-8186-e831dd8abdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        for i, l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
    "        \n",
    "    def forward(self, x): return reduce(lambda val, layer: layer(val), self.layers, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a54de183-5beb-4fa6-b99c-bdfae291c89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b90f4d80-9ae9-421f-9ec5-b573ca89e0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xb).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb0e4e7-2e9f-48b6-acc8-0864ed38da7d",
   "metadata": {},
   "source": [
    "## nn.ModuleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "740521cc-2201-4e0b-82df-36a99f048d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "259adc6e-936b-4500-abc1-d1b5f7db578f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialModel(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SequentialModel(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6999117a-f507-45b7-9fd0-77648f77bdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12, 0.96\n",
      "0.11, 0.96\n",
      "0.07, 0.98\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613e416c-8ca4-4d71-b971-e672db6534d3",
   "metadata": {},
   "source": [
    "## nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e34a6e3f-7622-4602-a7b0-916098c54559",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(m, nh),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(nh, 10)    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1a7366db-80e7-41b9-9b72-38dfc7716d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16, 0.94\n",
      "0.13, 0.96\n",
      "0.08, 0.96\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a2fe6bc4-9bbe-40a6-8cd9-d25b0a7f1a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.03, grad_fn=<NllLossBackward0>), tensor(1.))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "65f957b5-a52a-4e05-a096-16e04e68ce3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2eaf6e-08fe-4c57-b02e-1d04e93385ca",
   "metadata": {},
   "source": [
    "## optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a3c97cd5-50d7-400b-b44d-33d0b6415c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "166ab738-fc6a-4c00-8729-95cd40f7d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, params, lr=0.5): \n",
    "        self.params, self.lr = list(params), lr\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: \n",
    "                p -= p.grad * self.lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params: p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5e701be4-c582-46dd-a163-8a9ef31e3ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9f55c457-c95e-4246-b157-a8a9b812fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0b04d9b8-0569-4f72-9fa8-3a0675d5f860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18, 0.94\n",
      "0.13, 0.96\n",
      "0.11, 0.94\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n, i+bs))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023aeb91-4e28-4b64-a4f8-2436f0846bac",
   "metadata": {},
   "source": [
    "Pytorch already has the module `optim.SGD` for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b1166a80-e2a7-43df-90ab-fcc3631fc9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "58219b42-207c-4838-a155-3b2823bff3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2904e28b-4f80-4ce7-a585-3e4d137fb3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.33, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "loss_func(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8f6b7bbd-7611-4a35-8144-f127d58c973f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12, 0.98\n",
      "0.09, 0.98\n",
      "0.07, 0.98\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n, i + bs))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fda640-df2d-4427-b77c-fa7a001a82a9",
   "metadata": {},
   "source": [
    "## Dataset & Dataloader\n",
    "\n",
    "### Dataset\n",
    "Let's avoid having to constantly chop the data ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ac1cdd86-0676-4d19-a229-6d373ec5e69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Dataset():\n",
    "    def __init__(self, x, y): self.x, self.y = x, y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, i): return self.x[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0bcd781a-d561-4967-98fa-7f6cf5e4863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)\n",
    "assert len(train_ds) == len(x_train)\n",
    "assert len(valid_ds) == len(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0b69c981-60f1-437d-adc5-14bb1b728f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = train_ds[0:5]\n",
    "assert xb.shape == (5, 28*28)\n",
    "assert yb.shape == (5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6d6238f9-56d9-4c12-8411-2a2c5260ea5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dbd977e8-2749-41ff-8bd8-ba8da0c55fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17, 0.96\n",
      "0.11, 0.94\n",
      "0.09, 0.96\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        xb, yb = train_ds[i:min(n, i + bs)]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dbe40b-bfe8-4ff1-9bd5-9f2b1748f9b8",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "\n",
    "Let's make an iteradle that gives us the the minbatechs directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f2df5cb9-9cdd-4a10-8a15-e379791d5ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader():\n",
    "    def __init__(self, ds, bs): self.ds, self.bs = ds, bs\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds), self.bs):\n",
    "            yield self.ds[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dea0acf2-9b30-4460-8659-d7fe5586c46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = Dataloader(train_ds, bs)\n",
    "valid_dl = Dataloader(valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "db2a7bfc-d242-494c-8486-a0575143bf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 784]), torch.Size([50]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(valid_dl))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7174467d-dd89-40fc-b47b-32717017b436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 8, 6, 9, 6, 4, 5, 3, 8, 4, 5, 2, 3, 8, 4, 8, 1, 5, 0, 5, 9, 7, 4, 1, 0, 3, 0, 6, 2, 9, 9, 4, 1, 3, 6, 8, 0, 7, 7, 6, 8, 9, 0, 3,\n",
       "        8, 3, 7, 7, 8, 4])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d35e5b2c-5ae1-4271-b311-f67a56af01c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[0].view(28, 28));\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f4a0386c-df51-4b63-bd43-d20750f9e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a77a2fa3-40ac-4817-ae8f-da4aaa810bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs=3):\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "80b383d4-a2af-4d4f-9fb2-ac354dfab1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11, 0.98\n",
      "0.09, 0.98\n",
      "0.06, 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.03, grad_fn=<NllLossBackward0>), tensor(1.))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6defb1c-99e4-4b31-a126-4f4537632b84",
   "metadata": {},
   "source": [
    "## Random sampling\n",
    "\n",
    "Let's ensure that our training set is randomly ordered every iteration. This should not be the case for our validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "22139ceb-e2e3-491f-acd1-5f35ec59fddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def chunked(it, chunk_sz=1): \n",
    "    return iter(lambda: list(islice(it, chunk_sz)), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "206eb48c-c55e-41bb-9c7a-f7747faeb528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "class Sampler():\n",
    "    \"\"\"\n",
    "    Returns an iterator of indices for the given dataset. \n",
    "    These can possibly be shuffled\n",
    "    \"\"\"\n",
    "    def __init__(self, ds, shuffle=False): self.n, self.shuffle = len(ds), shuffle\n",
    "    def __iter__(self):\n",
    "        res = list(range(self.n))\n",
    "        if self.shuffle: random.shuffle(res)\n",
    "        return iter(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4c780036-7fdb-469a-82a2-7094129c8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = Sampler(train_ds)\n",
    "it = iter(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9cf7495f-a82a-4117-8bcb-6f14c37c5802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = Sampler(train_ds, shuffle=False)\n",
    "list(islice(ss, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "00b4b1cd-716b-45dc-a4d5-91cf23c41d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23306, 15791, 18685, 21551, 22961, 11112, 42778, 41672, 48385, 20415]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr = Sampler(train_ds, shuffle=True)\n",
    "list(islice(sr, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "67ac47ba-e40f-4dd8-b31b-5dda227c4e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSampler():\n",
    "    \"\"\"\n",
    "    Given a sampler and a batch size, returns an iterator of indices \n",
    "    of the given batch size\n",
    "    \"\"\"\n",
    "    def __init__(self, sampler, bs): self.sampler, self.bs = sampler, bs\n",
    "    def __iter__(self): yield from chunked(iter(self.sampler), chunk_sz=self.bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6b8b45da-1565-4528-9b68-74feb8953e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4],\n",
       " [5, 6, 7, 8, 9],\n",
       " [10, 11, 12, 13, 14],\n",
       " [15, 16, 17, 18, 19],\n",
       " [20, 21, 22, 23, 24]]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchs = BatchSampler(ss, 5)\n",
    "list(islice(batchs, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cd56454f-9834-4958-a921-82a6457e023f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[34858, 44380, 43578, 7694, 8122],\n",
       " [2276, 46032, 35959, 25900, 12769],\n",
       " [22783, 13521, 42260, 40459, 5947],\n",
       " [35760, 8040, 20511, 2669, 7015],\n",
       " [19547, 19415, 31260, 19602, 41029]]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchs = BatchSampler(sr, 5)\n",
    "list(islice(batchs, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5dd57e7f-2f37-4cc7-9409-18100af6121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    \"\"\"\n",
    "    Given a batch of pairs (x,y), stack them together\n",
    "    x*, y*\n",
    "    \"\"\"\n",
    "    xs, ys = zip(*b)\n",
    "    return torch.stack(xs), torch.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9d3fd551-227c-4bcd-ab4c-33ff23d5cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader():\n",
    "    \"\"\"\n",
    "    Return a collated iterator that's been batch sampled accordingly\n",
    "    \"\"\"\n",
    "    def __init__(self, ds, batchs, collate_fn=collate):\n",
    "        self.ds, self.batchs, self.collate_fn = ds, batchs, collate_fn\n",
    "    def __iter__(self): yield from (self.collate_fn(self.ds[i] for i in b) for b in self.batchs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d02ef240-7792-4ad5-8fc7-bd56fe249165",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = BatchSampler(Sampler(train_ds, shuffle=True), bs)\n",
    "valid_samp = BatchSampler(Sampler(valid_ds, shuffle=False), bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "91b3ef1c-6180-4637-ac3a-b3243f044682",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = Dataloader(train_ds, batchs=train_samp)\n",
    "valid_dl = Dataloader(valid_ds, batchs=valid_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d7c5eed4-411e-4494-9ccd-cede10d31ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb, yb = next(iter(valid_dl))\n",
    "plt.imshow(xb[0].view(28, 28));\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "636821f6-eac6-4187-85d3-cdba3bee8fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 784]), torch.Size([50]))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688dc2ef-0b72-4e5f-92a1-d7292644a95e",
   "metadata": {},
   "source": [
    "## Multiprocessing Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b6d6ce7c-29c0-4716-afc2-bc3378ddc4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "from fastcore.basics import store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a7391523-7595-4b38-9f9e-f32780a82c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([1, 1, 1, 0]))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[[3,6,8,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4b3b5475-05c1-4257-b356-03c9aaab6a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([1, 1, 1, 0]))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.__getitem__([3,6,8,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1a4e976d-b515-4627-ba34-2f2a0ae7c94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 1]))\n",
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 0]))\n"
     ]
    }
   ],
   "source": [
    "for o in map(train_ds.__getitem__, ([3,6], [8,1])): print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f2b7d8b5-02d9-44a7-9b0b-53f8a8d67664",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader():\n",
    "    \"\"\"\n",
    "    Creates a dataloader distributed along different processes\n",
    "    \"\"\"\n",
    "    def __init__(self, ds, batchs, n_workers=1, collate_fn=collate): store_attr()\n",
    "    def __iter__(self):\n",
    "        with mp.Pool(self.n_workers) as ex: \n",
    "            yield from ex.map(self.ds.__getitem__, iter(self.batchs))\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "01220a07-ddf5-43c8-a54e-0a5d1b4760f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = Dataloader(train_ds, batchs=train_samp, n_workers=2)\n",
    "it = iter(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b78d4da2-1923-435c-bd06-39d90a530281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 784]), torch.Size([50]))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(it)\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b786687-c1c8-47d8-b99e-4583285b5b29",
   "metadata": {},
   "source": [
    "## Pytorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "723380ce-a1ae-4d4c-b316-b25f38e6a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, BatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0a7cce01-748d-4582-9757-834897a57c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = BatchSampler(RandomSampler(train_ds), bs, drop_last=False)\n",
    "valid_samp = BatchSampler(SequentialSampler(valid_ds), bs, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9c32d25b-7740-46a8-9202-1b10ee825771",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_sampler=train_samp, collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, batch_sampler=valid_samp, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3f557641-097e-40af-8885-75103dfb909b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11, 0.94\n",
      "0.07, 0.98\n",
      "0.04, 0.98\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2bee80b0-5d4b-426c-9a00-682265e1d0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.14, grad_fn=<NllLossBackward0>), tensor(0.92))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e62f49-1c66-4221-ae44-5a29432b7b92",
   "metadata": {},
   "source": [
    "Pytorch can auto-create the sequentila/random samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "efa79096-7458-4197-b012-60950aec7a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True, num_workers=2)\n",
    "valid_dl = DataLoader(valid_ds, bs, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b47f0a3c-a762-488b-8d9d-e45363df7afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13, 0.94\n",
      "0.07, 0.96\n",
      "0.19, 0.94\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.09, grad_fn=<NllLossBackward0>), tensor(0.96))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "fit()\n",
    "\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "88e1f3c5-f3cf-4f88-9ae4-34440de5a2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([9, 1, 3]))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[[4,6,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "21c993b9-ffc3-4aec-b65d-022e6e75f2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, sampler=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, sampler=valid_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "782f5c75-0f0b-43c3-8cc6-e3ea5b158b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 50, 784]), torch.Size([1, 50]))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19684128-2b36-47e7-abe2-eeb18e154690",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "Call `model.train()` before training, and `model.eval()` before inference as there are certain layers such as `nn.Dropout` and `nn.BatchNorm2d` that behave differently depending on training or inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "95f4a56c-00c3-4afc-8c1b-b12915b3496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2699a96-502c-40ab-90d5-9041482c519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in trange(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tot_loss, tot_acc, count = 0., 0., 0\n",
    "            for xb, yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                n = len(xb)\n",
    "                count += n\n",
    "                tot_loss += loss_func(pred, yb).item() * n\n",
    "                tot_acc += accuracy(pred, yb).item() * n\n",
    "        print(epoch, tot_loss/count, tot_acc/count)\n",
    "    return tot_loss/count, tot_acc/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "fa822638-19f1-4d85-a341-e4807002b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
    "        DataLoader(valid_ds, batch_size=bs*2, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "aa2db078-c14a-4615-ad8e-a5108ffab1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ed442ef6-e7a7-4e84-9c03-613b0a3484e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ea390be302420ab652993030d38b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.15353523379191755 0.9556000047922134\n",
      "1 0.11415097464807332 0.9655000042915344\n",
      "2 0.11587181014940143 0.9667000061273575\n",
      "3 0.11414644016884268 0.9658000040054321\n",
      "4 0.10954055359703489 0.9703000056743621\n",
      "CPU times: user 2min 41s, sys: 773 ms, total: 2min 42s\n",
      "Wall time: 27.4 s\n"
     ]
    }
   ],
   "source": [
    "%time loss, acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ddc7b83-b346-4baa-b76a-f8de757a2193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nbdev\n",
      "  Downloading nbdev-2.3.12-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fastcore>=1.5.27 in /usr/local/lib/python3.9/dist-packages (from nbdev) (1.5.27)\n",
      "Collecting execnb>=0.1.4\n",
      "  Downloading execnb-0.1.5-py3-none-any.whl (13 kB)\n",
      "Collecting ghapi>=1.0.3\n",
      "  Downloading ghapi-1.0.3-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.9/dist-packages (from nbdev) (1.6.3)\n",
      "Collecting watchdog\n",
      "  Downloading watchdog-2.3.1-py3-none-manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: asttokens in /usr/local/lib/python3.9/dist-packages (from nbdev) (2.0.5)\n",
      "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from nbdev) (5.3.1)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.9/dist-packages (from execnb>=0.1.4->nbdev) (8.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from fastcore>=1.5.27->nbdev) (21.3)\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (from fastcore>=1.5.27->nbdev) (22.2.2)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from asttokens->nbdev) (1.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse->nbdev) (0.35.1)\n",
      "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.9/dist-packages (from ipython->execnb>=0.1.4->nbdev) (5.3.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython->execnb>=0.1.4->nbdev) (0.7.5)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython->execnb>=0.1.4->nbdev) (5.1.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.9/dist-packages (from ipython->execnb>=0.1.4->nbdev) (2.12.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython->execnb>=0.1.4->nbdev) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython->execnb>=0.1.4->nbdev) (3.0.30)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython->execnb>=0.1.4->nbdev) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/dist-packages (from ipython->execnb>=0.1.4->nbdev) (0.1.3)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.9/dist-packages (from ipython->execnb>=0.1.4->nbdev) (63.1.0)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.9/dist-packages (from ipython->execnb>=0.1.4->nbdev) (0.3.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/dist-packages (from ipython->execnb>=0.1.4->nbdev) (0.18.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging->fastcore>=1.5.27->nbdev) (3.0.9)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython->execnb>=0.1.4->nbdev) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect>4.3->ipython->execnb>=0.1.4->nbdev) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->execnb>=0.1.4->nbdev) (0.2.5)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.9/dist-packages (from stack-data->ipython->execnb>=0.1.4->nbdev) (0.2.2)\n",
      "Requirement already satisfied: executing in /usr/local/lib/python3.9/dist-packages (from stack-data->ipython->execnb>=0.1.4->nbdev) (0.8.3)\n",
      "Installing collected packages: watchdog, ghapi, execnb, nbdev\n",
      "Successfully installed execnb-0.1.5 ghapi-1.0.3 nbdev-2.3.12 watchdog-2.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e60a7fe3-e441-4ad6-bd61-a1215e386034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062260a0-df9e-457f-95bc-fc2c4f31106b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
